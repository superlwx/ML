{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import testCases #参见资料包，或者在文章底部copy\n",
    "from dnn_utils import sigmoid, sigmoid_backward, relu, relu_backward #参见资料包\n",
    "import lr_utils #参见资料包，或者在文章底部copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    W1=np.random.randn(n_h,n_x)*0.01\n",
    "    b1=np.zeros((n_h,1))\n",
    "    W2=np.random.randn(n_y,n_h)*0.01\n",
    "    b2=np.zeros((n_y,1))\n",
    "    parameters={\"W1\":W1,\n",
    "                \"b1\":b1,\n",
    "                \"W2\":W2,\n",
    "                \"b2\":b2}\n",
    "    return parameters\n",
    "\n",
    "def initialize_parameters_deep(layers_dims):\n",
    "    parameters={}\n",
    "    L=len(layers_dims)\n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\"+str(l)]=np.random.randn(layers_dims[l],layers_dims[l-1])/ np.sqrt(layers_dims[l - 1])\n",
    "        parameters[\"b\"+str(l)]=np.zeros((layers_dims[l],1))\n",
    "    return parameters\n",
    "def linear_forward(A,W,b):\n",
    "    Z=np.dot(W,A)+b\n",
    "    cache=(A,W,b)\n",
    "    return Z,cache\n",
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    if activation==\"sigmoid\":\n",
    "        Z,linear_cache=linear_forward(A_prev,W,b)\n",
    "        A,activation_cache=sigmoid(Z)\n",
    "    if activation==\"relu\":\n",
    "        Z,linear_cache=linear_forward(A_prev,W,b)\n",
    "        A,activation_cache=relu(Z)\n",
    "    cache=(linear_cache,activation_cache)\n",
    "    return A,cache\n",
    "def L_model_forward(X,parameters):\n",
    "    A=X\n",
    "    L=len(parameters)//2\n",
    "    caches=[]\n",
    "    for l in range(1,L):\n",
    "        A_prev=A\n",
    "        A,cache=linear_activation_forward(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
    "        caches.append(cache)\n",
    "    AL,cache=linear_activation_forward(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    return AL,caches\n",
    "def compute_cost(AL,Y):\n",
    "    m=Y.shape[1]\n",
    "    cost=-np.sum(np.multiply(np.log(AL),Y)+np.multiply(np.log(1-AL),1-Y))/m;\n",
    "    cost=np.squeeze(cost)\n",
    "    return cost\n",
    "def linear_backward(dZ,cache):\n",
    "    A_prev,W,b=cache\n",
    "    m=A_prev.shape[1]\n",
    "    dW=np.dot(dZ,A_prev.T)/m\n",
    "    db=np.sum(dZ,axis=1,keepdims=True)/m\n",
    "    dA_prev=np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db\n",
    "def linear_activation_backward(dA,cache,activation=\"relu\"):\n",
    "    linear_cache,activation_cache=cache\n",
    "    if activation==\"sigmoid\":\n",
    "        dZ=sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
    "    if activation==\"relu\":\n",
    "        dZ=relu_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db=linear_backward(dZ,linear_cache)\n",
    "    return dA_prev,dW,db\n",
    "def L_model_backward(AL,Y,caches):\n",
    "    grads={}\n",
    "    L=len(caches)\n",
    "    cache=caches[L-1]\n",
    "    AL.reshape(Y.shape)\n",
    "    dAL=-(np.divide(Y,AL)-np.divide(1-Y,1-AL))\n",
    "    grads[\"dA\"+str(L)],grads[\"dW\"+str(L)],grads[\"db\"+str(L)]=linear_activation_backward(dAL,cache,\"sigmoid\")\n",
    "    for l in reversed(range(L-1)):\n",
    "        cache=caches[l]\n",
    "        dA_prev_temp,dW_temp,db_temp=linear_activation_backward(grads[\"dA\"+str(l+2)],cache,\"relu\")\n",
    "        grads[\"dA\"+str(l+1)],grads[\"dW\"+str(l+1)],grads[\"db\"+str(l+1)]=dA_prev_temp,dW_temp,db_temp\n",
    "    return grads\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L=len(parameters)//2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\"+str(l+1)]=parameters[\"W\"+str(l+1)]-learning_rate*grads[\"dW\"+str(l+1)]\n",
    "        parameters[\"b\"+str(l+1)]=parameters[\"b\"+str(l+1)]-learning_rate*grads[\"db\"+str(l+1)]\n",
    "    return parameters\n",
    "def two_layer_model(X,Y,layers_dims,learning_rate=0.0075,num_iterations=3000,print_cost=False,isPlot=True):\n",
    "    (n_x,n_h,n_y)=layers_dims\n",
    "    costs=[]\n",
    "    grads = {}\n",
    "    parameters=initialize_parameters(n_x,n_h,n_y)\n",
    "    for i in range(num_iterations):\n",
    "        W1=parameters[\"W1\"]\n",
    "        b1=parameters[\"b1\"]\n",
    "        W2=parameters[\"W2\"]\n",
    "        b2=parameters[\"b2\"]\n",
    "        A1,cache1=linear_activation_forward(X,W1,b1,\"relu\")\n",
    "        A2,cache2=linear_activation_forward(A1,W2,b2,\"sigmoid\")\n",
    "        cost=compute_cost(A2,Y)\n",
    "        Y = Y.reshape(A2.shape)\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        dA1,dW2,db2=linear_activation_backward(dA2,cache2,\"sigmoid\")\n",
    "        dA0,dW1,db1=linear_activation_backward(dA1,cache1,\"relu\")\n",
    "        grads={\"dW2\":dW2,\n",
    "                    \"dW1\":dW1,\n",
    "                    \"db2\":db2,\n",
    "                    \"db1\":db1}\n",
    "        parameters=update_parameters(parameters,grads,learning_rate)\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print(\"第\", i ,\"次迭代，成本值为：\" ,np.squeeze(cost))\n",
    "    return parameters\n",
    "def predict(X, y, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # 神经网络的层数\n",
    "    p = np.zeros((1,m))\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    print(\"准确度为: \"  + str(float(np.sum((p == y))/m)))\n",
    "\n",
    "    return p\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate=0.0075, num_iterations=3000, print_cost=False,isPlot=True):\n",
    "    parameters=initialize_parameters_deep(layers_dims)\n",
    "    costs=[]\n",
    "    for i in range(num_iterations):\n",
    "        AL,caches =L_model_forward(X,parameters)\n",
    "        cost=compute_cost(AL,Y)\n",
    "        grads=L_model_backward(AL,Y,caches)\n",
    "        parameters=update_parameters(parameters,grads,learning_rate)\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print(\"第\", i ,\"次迭代，成本值为：\" ,np.squeeze(cost))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = lr_utils.load_dataset()\n",
    "\n",
    "train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T \n",
    "test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "train_x = train_x_flatten / 255\n",
    "train_y = train_set_y\n",
    "test_x = test_x_flatten / 255\n",
    "test_y = test_set_y\n",
    "n_x = 12288\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x,n_h,n_y)\n",
    "\n",
    "parameters = two_layer_model(train_x, train_set_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True,isPlot=True)\n",
    "print(predict(test_x,test_y,parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 次迭代，成本值为： 0.6931472742228205\n",
      "第 100 次迭代，成本值为： 0.6780103488766552\n",
      "第 200 次迭代，成本值为： 0.6675993040306714\n",
      "第 300 次迭代，成本值为： 0.6604214282401469\n",
      "第 400 次迭代，成本值为： 0.6554574039916994\n",
      "第 500 次迭代，成本值为： 0.6520130925489744\n",
      "第 600 次迭代，成本值为： 0.6496154961263259\n",
      "第 700 次迭代，成本值为： 0.6479414595763608\n",
      "第 800 次迭代，成本值为： 0.6467693997424374\n",
      "第 900 次迭代，成本值为： 0.6459467841145865\n",
      "第 1000 次迭代，成本值为： 0.6453681781174686\n",
      "第 1100 次迭代，成本值为： 0.6449604393320985\n",
      "第 1200 次迭代，成本值为： 0.6446726427574252\n",
      "第 1300 次迭代，成本值为： 0.6444692214156432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7437a9a65d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m12288\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#  5-layer model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misPlot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-6754ebfff445>\u001b[0m in \u001b[0;36mL_layer_model\u001b[1;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost, isPlot)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mcosts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaches\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mL_model_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_model_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6754ebfff445>\u001b[0m in \u001b[0;36mL_model_forward\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mA_prev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinear_activation_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mcaches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinear_activation_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6754ebfff445>\u001b[0m in \u001b[0;36mlinear_activation_forward\u001b[1;34m(A_prev, W, b, activation)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinear_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinear_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6754ebfff445>\u001b[0m in \u001b[0;36mlinear_forward\u001b[1;34m(A, W, b)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mZ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes = lr_utils.load_dataset()\n",
    "\n",
    "train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T \n",
    "test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "train_x = train_x_flatten / 255\n",
    "train_y = train_set_y\n",
    "test_x = test_x_flatten / 255\n",
    "test_y = test_set_y\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model\n",
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True,isPlot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确度为: 0.74\n",
      "[[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      "  1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      "  1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(predict(test_x,test_y,parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 209)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
