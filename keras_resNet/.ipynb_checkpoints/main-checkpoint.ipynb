{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import kt_utils \n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    X_input=Input(input_shape)\n",
    "    X=ZeroPadding2D((3,3))(X_input)\n",
    "    X=Conv2D(32,(7,7),strides=(1,1),name=\"conv0\")(X)\n",
    "    X=BatchNormalization(axis=3,name=\"bn0\")(X)\n",
    "    X=Activation(\"relu\")(X)\n",
    "    X=MaxPooling2D((2,2),name=\"max_pool\")(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(1,activation='sigmoid',name=\"fc\")(X)\n",
    "    model=Model(inputs=X_input,outputs=X,name=\"happymodel\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.3191 - acc: 0.5667\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.7329 - acc: 0.7583\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.5291 - acc: 0.7933\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2273 - acc: 0.9117\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.1770 - acc: 0.9300\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.1433 - acc: 0.9383A: 0s - loss: 0.1377 - acc: 0.94\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.1053 - acc: 0.9650\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.1011 - acc: 0.9683\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0873 - acc: 0.9717\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0751 - acc: 0.9733\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0602 - acc: 0.9817\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0575 - acc: 0.9850\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0498 - acc: 0.9833\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0448 - acc: 0.9867\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0389 - acc: 0.9917\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0384 - acc: 0.9900A: 1s - loss: 0.0401 - a\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0398 - acc: 0.9900\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0646 - acc: 0.9767\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0394 - acc: 0.9917\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0313 - acc: 0.9933\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0256 - acc: 0.9900\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0283 - acc: 0.9933\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0476 - acc: 0.9833\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0307 - acc: 0.9917\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0376 - acc: 0.9933\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0225 - acc: 0.9967\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0180 - acc: 0.9967\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0236 - acc: 0.9900\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0164 - acc: 0.9967\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0145 - acc: 0.9967\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0097 - acc: 0.9967\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0123 - acc: 0.9967\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0136 - acc: 0.9967\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0118 - acc: 0.9983\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0233 - acc: 0.9933\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0104 - acc: 0.9967\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "误差值 = 0.0809639526406924\n",
      "准确度 = 0.9666666706403096\n"
     ]
    }
   ],
   "source": [
    "X_train_orig,Y_train_orig,X_test_orig,Y_test_orig,_=kt_utils.load_dataset()\n",
    "X_train=X_train_orig/255\n",
    "X_test=X_test_orig/255\n",
    "Y_train=Y_train_orig.T\n",
    "Y_test=Y_test_orig.T\n",
    "happymodel=HappyModel(X_train.shape[1:])\n",
    "happymodel.compile(\"adam\",\"binary_crossentropy\", metrics=['accuracy'])\n",
    "happymodel.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "#评估模型\n",
    "preds = happymodel.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "print (\"误差值 = \" + str(preds[0]))\n",
    "print (\"准确度 = \" + str(preds[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-32dc82df7086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhappymodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'happy_model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhappymodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         raise OSError(\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot_model(happymodel, to_file='happy_model.png')\n",
    "SVG(model_to_dot(happymodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    F1,F2,F3=filters\n",
    "    X_shortcut=X\n",
    "    \n",
    "    X=Conv2D(F1,kernel_size=(1,1),strides=(1,1),padding=\"valid\",name=conv_name_base+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X=Activation(\"relu\")(X)\n",
    "    \n",
    "    X=Conv2D(F2,kernel_size=(f,f),strides=(1,1),padding=\"same\",kernel_initializer=glorot_uniform(seed=0),name=conv_name_base+\"2b\")(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X=Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "    ##没有ReLU激活函数\n",
    "\n",
    "    #最后一步：\n",
    "    ##将捷径与输入加在一起\n",
    "    X = Add()([X,X_shortcut])\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [ 0.94823   -0.         1.1610144  2.747859  -0.         1.36677  ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    A = identity_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "\n",
    "    test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    实现图5的卷积块\n",
    "\n",
    "    参数：\n",
    "        X - 输入的tensor类型的变量，维度为( m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f - 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters - 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage - 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block - 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "        s - 整数，指定要使用的步幅\n",
    "\n",
    "    返回：\n",
    "        X - 卷积块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "\n",
    "    #获取过滤器数量\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    #保存输入数据\n",
    "    X_shortcut = X\n",
    "\n",
    "    #主路径\n",
    "    ##主路径第一部分\n",
    "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    ##主路径第二部分\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    ##主路径第三部分\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "\n",
    "    #捷径\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"1\", kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3,name=bn_name_base+\"1\")(X_shortcut)\n",
    "\n",
    "    #最后一步\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [ 0.09018463  1.2348979   0.46822023  0.03671761 -0.          0.65516603]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "\n",
    "    A = convolutional_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    test.run(tf.global_variables_initializer())\n",
    "\n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "\n",
    "    test.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64,64,3),classes=6):\n",
    "    \"\"\"\n",
    "    实现ResNet50\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    参数：\n",
    "        input_shape - 图像数据集的维度\n",
    "        classes - 整数，分类数\n",
    "\n",
    "    返回：\n",
    "        model - Keras框架的模型\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #定义tensor类型的输入数据\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    #0填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "    #stage1\n",
    "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "\n",
    "    #stage2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "\n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "\n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "\n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "\n",
    "    #均值池化层\n",
    "    X = AveragePooling2D(pool_size=(2,2),padding=\"same\")(X)\n",
    "\n",
    "    #输出层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    #创建模型\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = resnets_utils.load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = resnets_utils.convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1080/1080 [==============================] - 45s 41ms/step - loss: 2.6668 - acc: 0.3713\n",
      "Epoch 2/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 0.9823 - acc: 0.7111\n",
      "Epoch 3/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 1.2522 - acc: 0.6722\n",
      "Epoch 4/20\n",
      "1080/1080 [==============================] - 32s 30ms/step - loss: 0.7000 - acc: 0.7537\n",
      "Epoch 5/20\n",
      "1080/1080 [==============================] - 33s 31ms/step - loss: 0.3265 - acc: 0.8769\n",
      "Epoch 6/20\n",
      "1080/1080 [==============================] - 32s 30ms/step - loss: 0.3813 - acc: 0.8750\n",
      "Epoch 7/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 0.1894 - acc: 0.9315\n",
      "Epoch 8/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 1.8778 - acc: 0.6324\n",
      "Epoch 9/20\n",
      "1080/1080 [==============================] - 32s 30ms/step - loss: 2.3756 - acc: 0.4648\n",
      "Epoch 10/20\n",
      "1080/1080 [==============================] - 32s 30ms/step - loss: 1.2387 - acc: 0.6167\n",
      "Epoch 11/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 2.0464 - acc: 0.5500\n",
      "Epoch 12/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 1.3139 - acc: 0.6306\n",
      "Epoch 13/20\n",
      "1080/1080 [==============================] - 33s 31ms/step - loss: 0.8562 - acc: 0.7500\n",
      "Epoch 14/20\n",
      "1080/1080 [==============================] - 33s 31ms/step - loss: 0.6127 - acc: 0.8000\n",
      "Epoch 15/20\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 0.5408 - acc: 0.8417\n",
      "Epoch 16/20\n",
      "1080/1080 [==============================] - 33s 31ms/step - loss: 0.4468 - acc: 0.8343\n",
      "Epoch 17/20\n",
      "1080/1080 [==============================] - 36s 33ms/step - loss: 0.2875 - acc: 0.9019\n",
      "Epoch 18/20\n",
      "1080/1080 [==============================] - 38s 36ms/step - loss: 0.2406 - acc: 0.9213\n",
      "Epoch 19/20\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 0.1561 - acc: 0.9519\n",
      "Epoch 20/20\n",
      "1080/1080 [==============================] - 38s 35ms/step - loss: 0.1942 - acc: 0.9481\n",
      "120/120 [==============================] - 2s 20ms/step\n",
      "误差值 = 0.32412979106108347\n",
      "准确率 = 0.8833333373069763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet50(input_shape=(64,64,3),classes=6)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train,Y_train,epochs=20,batch_size=32)\n",
    "preds = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 4s 32ms/step\n",
      "误差值 = 0.32412979106108347\n",
      "准确率 = 0.8833333373069763\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"happymodel.h5\")\n",
    "preds = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
